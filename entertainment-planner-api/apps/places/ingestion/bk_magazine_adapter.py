"""
BK Magazine –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ –º–µ—Å—Ç–∞—Ö
–°–ª–µ–¥—É–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ MVP –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ BK Magazine
"""
import re
import time
import requests
from bs4 import BeautifulSoup, SoupStrainer
from typing import List, Dict, Optional, Any
from urllib.parse import urljoin, urlparse
import logging

logger = logging.getLogger(__name__)


class BKMagazineAdapter:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ BK Magazine"""
    
    def __init__(self, base_url: str = "https://bk.asia-city.com", rate_limit: float = 1.0):
        self.base_url = base_url
        self.rate_limit = rate_limit
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
        })
    
    def _make_request(self, url: str) -> Optional[BeautifulSoup]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å —Å rate limiting"""
        try:
            time.sleep(self.rate_limit)  # –í–µ–∂–ª–∏–≤—ã–π rate limit
            response = self.session.get(url, timeout=60)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'lxml')
            
            # –û—á–∏—â–∞–µ–º HTML –æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            self._clean_html(soup)
            
            return soup
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {url}: {e}")
            return None
    
    def _clean_html(self, soup: BeautifulSoup):
        """–£–¥–∞–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ HTML —ç–ª–µ–º–µ–Ω—Ç—ã"""
        # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
        for script in soup(["script", "style", "noscript"]):
            script.decompose()
        
        # –£–¥–∞–ª—è–µ–º —Ä–µ–∫–ª–∞–º–Ω—ã–µ –±–ª–æ–∫–∏
        for ad in soup.find_all(class_=re.compile(r'ad|advertisement|banner', re.I)):
            ad.decompose()
    
    def parse_article_page(self, article_url: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç—å–∏ BK Magazine –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Å—Ç —Å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–∞"""
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç—å–∏: {article_url}")
        
        soup = self._make_request(article_url)
        if not soup:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {article_url}")
            return []
        
        try:
            # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å—Ç–∞—Ç—å–∏
            article_type = self._detect_article_type(article_url, soup)
            logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø —Å—Ç–∞—Ç—å–∏: {article_type}")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            places = self._extract_places(soup, article_type)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            places = self._remove_duplicates(places)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(places)} –º–µ—Å—Ç –≤ —Å—Ç–∞—Ç—å–µ")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—Ç
            for i, place in enumerate(places[:3], 1):
                logger.info(f"–ú–µ—Å—Ç–æ {i}: {place['title']}...")
            
            return places
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç–∞—Ç—å–∏ {article_url}: {e}")
            return []
    
    def _detect_article_type(self, url: str, soup: BeautifulSoup) -> str:
        """–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å—Ç–∞—Ç—å–∏ BK Magazine"""
        url_lower = url.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ URL
        if 'restaurants' in url_lower:
            return 'restaurants'
        elif 'nightlife' in url_lower or 'bars' in url_lower:
            return 'nightlife'
        elif 'spa' in url_lower or 'health' in url_lower:
            return 'spa'
        elif 'breakfast' in url_lower:
            return 'breakfast'
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        title = soup.find('title')
        if title:
            title_text = title.get_text().lower()
            if any(word in title_text for word in ['restaurant', 'dining', 'food', 'cuisine']):
                return 'restaurants'
            elif any(word in title_text for word in ['nightlife', 'bar', 'cocktail', 'club', 'pub']):
                return 'nightlife'
            elif any(word in title_text for word in ['spa', 'wellness', 'massage']):
                return 'spa'
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º h2
        h2_tags = soup.find_all('h2')
        restaurant_count = 0
        nightlife_count = 0
        
        for h2 in h2_tags[:10]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 10 –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            text = h2.get_text().lower()
            if any(word in text for word in ['bar', 'cocktail', 'pub', 'club', 'nightlife', 'lounge']):
                nightlife_count += 1
            elif any(word in text for word in ['restaurant', 'cafe', 'dining', 'food']):
                restaurant_count += 1
        
        if nightlife_count > restaurant_count:
            return 'nightlife'
        elif restaurant_count > 0:
            return 'restaurants'
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return 'general'
    
    def _extract_places(self, soup: BeautifulSoup, article_type: str = 'general') -> List[Dict[str, Any]]:
        """–ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Å—Ç –∏–∑ —Å—Ç–∞—Ç—å–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞"""
        places = []
        seen_titles = set()  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å—Ç–∞—Ç—å–∏
        if article_type == 'nightlife':
            places = self._extract_nightlife_places(soup, seen_titles)
        elif article_type == 'restaurants':
            places = self._extract_restaurant_places(soup, seen_titles)
        else:
            places = self._extract_general_places(soup, seen_titles)
        
        return places
    
    def _extract_nightlife_places(self, soup: BeautifulSoup, seen_titles: set) -> List[Dict[str, Any]]:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–æ—á–Ω—ã—Ö –∑–∞–≤–µ–¥–µ–Ω–∏–π —Å —Ç–æ—á–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –æ–ø–∏—Å–∞–Ω–∏–π"""
        places = []
        
        # –ú–µ—Ç–æ–¥ 1: –ò—â–µ–º h2 –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è –∑–∞–≤–µ–¥–µ–Ω–∏–π)
        h2_tags = soup.find_all('h2')
        
        for h2 in h2_tags:
            title = h2.get_text().strip()
            
            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç "Photo:" –∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
            if title.startswith('Photo:'):
                continue
            if 'Photo:' in title:
                title = title.split('Photo:')[0].strip()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
            if not self._is_valid_place_name(title) or len(title) < 3:
                continue
            
            # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
            if title.lower() in seen_titles:
                continue
            seen_titles.add(title.lower())
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –Ω–æ—á–Ω—ã—Ö –∑–∞–≤–µ–¥–µ–Ω–∏–π
            description = self._find_description_for_place(h2)
            
            place = {
                'title': title,
                'detail_url': None,
                'teaser': description,
                'address_fallback': None,  # –ù–µ —Å–æ–±–∏—Ä–∞–µ–º –∞–¥—Ä–µ—Å–∞
                'hours_fallback': None,    # –ù–µ —Å–æ–±–∏—Ä–∞–µ–º —á–∞—Å—ã
                'phone_fallback': None,    # –ù–µ —Å–æ–±–∏—Ä–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã
                'number': len(places) + 1
            }
            places.append(place)
        
        # –ú–µ—Ç–æ–¥ 2: –ò—â–µ–º –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö h2 (–¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–∏–ø–∞ "–ª—É—á—à–∏–µ –∑–∞–≤—Ç—Ä–∞–∫–∏")
        h2_tags = soup.find_all('h2')
        
        for h2 in h2_tags:
            title = h2.get_text().strip()
            
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "Finalist:" –µ—Å–ª–∏ –µ—Å—Ç—å
            if title.lower().startswith('finalist:'):
                title = title[9:].strip()  # –£–±–∏—Ä–∞–µ–º "Finalist:" –∏ –ø—Ä–æ–±–µ–ª—ã
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
            if not self._is_valid_place_name(title) or len(title) < 3:
                continue
            
            # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
            if title.lower() in seen_titles:
                continue
            seen_titles.add(title.lower())
            
            # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –º–µ—Å—Ç–∞
            description = self._find_description_for_place(h2)
            
            place = {
                'title': title,
                'detail_url': None,
                'teaser': description,
                'address_fallback': None,  # –ù–µ —Å–æ–±–∏—Ä–∞–µ–º –∞–¥—Ä–µ—Å–∞
                'hours_fallback': None,    # –ù–µ —Å–æ–±–∏—Ä–∞–µ–º —á–∞—Å—ã
                'phone_fallback': None,    # –ù–µ —Å–æ–±–∏—Ä–∞–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã
                'number': len(places) + 1
            }
            places.append(place)
        
        return places
    
    def _extract_restaurant_places(self, soup: BeautifulSoup, seen_titles: set) -> List[Dict[str, Any]]:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–∑–≤–∞–Ω–∏–π"""
        places = []
        
        # –ò—â–µ–º h1 –∏ h2 –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤)
        h1_tags = soup.find_all('h1')
        h2_tags = soup.find_all('h2')
        all_headers = h1_tags + h2_tags
        
        for header in all_headers:
            title = header.get_text().strip()
            
            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç "Photo:" –∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
            if title.startswith('Photo:'):
                continue
            if 'Photo:' in title:
                title = title.split('Photo:')[0].strip()
            
            # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            excluded_titles = [
                'Leave a Comment', 'Latest News', 'New Places', 'Categories',
                'Information', 'Connect', 'Advertisement', 'Advertisement'
            ]
            if title in excluded_titles:
                continue
            
            if self._is_valid_place_name(title) and title not in seen_titles:
                seen_titles.add(title)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–∑–≤–∞–Ω–∏—è
                description = self._find_description_for_place(header)
                
                # –ò—â–µ–º –∞–¥—Ä–µ—Å –≤ —Å–ª–µ–¥—É—é—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ
                address = self._find_address_for_place(header)
                
                place = {
                    'title': title,
                    'teaser': description or '',
                    'address_fallback': address,
                    'phone_fallback': None,
                    'number': len(places) + 1
                }
                places.append(place)
        
        return places
    
    def _extract_general_places(self, soup: BeautifulSoup, seen_titles: set) -> List[Dict[str, Any]]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Å—Ç —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–∑–≤–∞–Ω–∏–π"""
        places = []
        
        # –ú–µ—Ç–æ–¥ 1: –ò—â–µ–º –≤—Å–µ –∂–∏—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç)
        bold_tags = soup.find_all(['b', 'strong'])
        
        for bold in bold_tags:
            title = bold.get_text().strip()
            
            if self._is_valid_place_name(title) and title not in seen_titles:
                seen_titles.add(title)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–∑–≤–∞–Ω–∏—è
                description = self._find_description_for_place(bold)
                
                # –ò—â–µ–º –∞–¥—Ä–µ—Å
                address = self._find_address_for_place(bold)
                
                place = {
                    'title': title,
                    'teaser': description or '',
                    'address_fallback': address,
                    'phone_fallback': None,
                    'number': len(places) + 1
                }
                places.append(place)
        
        return places
    
    
    def _contains_place_name(self, text: str, place_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞"""
        if not place_name or not text:
            return False
        
        # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        clean_name = place_name.replace('Photo:', '').replace('Photo', '').strip()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞
        name_words = [word.strip() for word in clean_name.split() if len(word.strip()) > 2]
        
        if not name_words:
            return False
        
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Ö–æ—Ç—è –±—ã 2 —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
        found_words = 0
        for word in name_words:
            if word.lower() in text_lower:
                found_words += 1
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª—å—à–µ –ø–æ–ª–æ–≤–∏–Ω—ã —Å–ª–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è - —ç—Ç–æ –Ω–∞—à–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        return found_words >= len(name_words) // 2 + 1
    
    def _find_address_for_place(self, bold_elem) -> Optional[str]:
        """–ü–æ–∏—Å–∫ –∞–¥—Ä–µ—Å–∞ –¥–ª—è –º–µ—Å—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –∞–¥—Ä–µ—Å–∞ –≤ —Å–ª–µ–¥—É—é—â–µ–º —ç–ª–µ–º–µ–Ω—Ç–µ
        next_elem = bold_elem.find_next(['p', 'div'])
        if next_elem and next_elem.get_text().strip():
            text = next_elem.get_text().strip()
            # –ò—â–µ–º –∞–¥—Ä–µ—Å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            address_indicators = ['road', 'soi', 'street', 'avenue', 'bangkok', 'thailand']
            if any(indicator in text.lower() for indicator in address_indicators):
                return text
        return None
    
    def _find_description_for_place(self, bold_elem) -> Optional[str]:
        """–ì–ò–ë–†–ò–î–ù–´–ô –ø–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è: –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º + GPT-–ø–æ–º–æ—â–Ω–∏–∫"""
        place_name = bold_elem.get_text().strip()
        
        # –≠–¢–ê–ü 1: –ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º (–±—ã—Å—Ç—Ä—ã–π)
        description = self._find_description_creative(bold_elem, place_name)
        
        if description:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ–ø–∏—Å–∞–Ω–∏—è
            if self._contains_place_name(description, place_name):
                return description  # –•–æ—Ä–æ—à–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –º–µ—Å—Ç–∞
            else:
                # –û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è - –ø—Ä–æ–±—É–µ–º GPT –¥–ª—è –ª—É—á—à–µ–≥–æ
                gpt_description = self._find_description_with_gpt(bold_elem, place_name)
                if gpt_description and self._contains_place_name(gpt_description, place_name):
                    return gpt_description  # GPT –Ω–∞—à–µ–ª –ª—É—á—à–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                else:
                    # –ï—Å–ª–∏ GPT –Ω–µ –Ω–∞—à–µ–ª –ª—É—á—à–µ–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
                    if self._is_good_description(description, place_name):
                        return description  # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–µ–µ
                    else:
                        # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–ª–æ—Ö–æ–µ, –ø—Ä–æ–±—É–µ–º GPT –∫–∞–∫ fallback
                        gpt_fallback = self._find_description_with_gpt(bold_elem, place_name)
                        return gpt_fallback if gpt_fallback else description
        
        # –≠–¢–ê–ü 2: GPT-–ø–æ–º–æ—â–Ω–∏–∫ (—É–º–Ω—ã–π) –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        description = self._find_description_with_gpt(bold_elem, place_name)
        if description:
            return description
        
        return None
    
    def _is_good_description(self, description: str, place_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ö–æ—Ä–æ—à–∏–º –¥–ª—è –º–µ—Å—Ç–∞"""
        if not description or len(description) < 100:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –æ–±—â–∏–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏
        article_indicators = [
            'our big breakfast list is back',
            'this year we are happy to introduce',
            'the breakfast issue is a big deal',
            'you love it we love it',
            'jump to:',
            'back to top',
            'by bk staff',
            'bangkok things to-do',
            'for fans of bangkok cafes',
            'so many restaurants come and go',
            'it was a big win for the sukhumvit',
            'there are four holey bakery outlets',
            'despite being hidden away',
            'from the minds behind bangkok'
        ]
        
        description_lower = description.lower()
        if any(indicator in description_lower for indicator in article_indicators):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≤–µ–¥–µ–Ω–∏–∏
        venue_indicators = [
            'serves', 'offers', 'specializes', 'features', 'located',
            'menu', 'food', 'drink', 'coffee', 'breakfast', 'lunch',
            'dinner', 'price', 'cost', 'bath', 'baht', 'b120', 'b150',
            'b200', 'b300', 'b400', 'b500', 'b600', 'b700', 'b800',
            'b900', 'b1000', 'restaurant', 'cafe', 'bakery', 'bar',
            'kitchen', 'dining', 'eatery', 'spot', 'venue', 'place'
        ]
        
        venue_count = sum(1 for indicator in venue_indicators if indicator in description_lower)
        
        # –ë–æ–ª–µ–µ –≥–∏–±–∫–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ö–æ—Ä–æ—à–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
        if venue_count >= 3:
            return True
        elif venue_count >= 2 and len(description) > 200:
            return True
        elif venue_count >= 1 and len(description) > 400:
            return True
        
        return False
    
    def _find_description_creative(self, bold_elem, place_name: str) -> Optional[str]:
        """–ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è —Å —É–º–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π"""
        # –°–æ–∑–¥–∞–µ–º –∑–æ–Ω—ã –ø–æ–∏—Å–∫–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
        search_zones = self._create_search_zones(bold_elem)
        
        # –ü–†–ò–û–†–ò–¢–ï–¢ 1: –ü–æ–∏—Å–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç–∞ (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π)
        for zone in search_zones:
            for element in zone['elements']:
                text = element.get_text().strip()
                if len(text) > 100 and self._is_venue_description(text):
                    if self._contains_place_name(text, place_name):
                        description = self._clean_description_text(text)
                        if len(description) > 50:
                            return description
        
        # –ü–†–ò–û–†–ò–¢–ï–¢ 2: Fallback –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π)
        for zone in search_zones:
            for element in zone['elements']:
                text = element.get_text().strip()
                if len(text) > 100 and self._is_venue_description(text):
                    description = self._clean_description_text(text)
                    if len(description) > 50:
                        return description
        
        return None
    
    def _find_description_with_gpt(self, bold_elem, place_name: str) -> Optional[str]:
        """–£–ú–ù–´–ô GPT-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π"""
        try:
            import openai
            
            # –°–æ–∑–¥–∞–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π HTML –∫–æ–Ω—Ç–µ–∫—Å—Ç (–º–∞–∫—Å–∏–º—É–º 1500 —Ç–æ–∫–µ–Ω–æ–≤)
            html_context = self._create_smart_html_context(bold_elem, place_name)
            
            # –°–æ–∑–¥–∞–µ–º GPT –∫–ª–∏–µ–Ω—Ç
            client = openai.OpenAI(api_key="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")
            
            # –ß–ï–¢–ö–ò–ô –ü–†–û–ú–ü–¢ –¥–ª—è GPT
            prompt = f"""–ê–ù–ê–õ–ò–ó HTML –î–õ–Ø –ü–û–ò–°–ö–ê –û–ü–ò–°–ê–ù–ò–Ø –ú–ï–°–¢–ê

–ó–ê–î–ê–ß–ê: –ù–∞–π–¥–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –º–µ—Å—Ç–∞ "{place_name}"

HTML –ö–û–ù–¢–ï–ö–°–¢:
{html_context}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ù–∞–π–¥–∏ —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Å—Ç–æ "{place_name}"
2. –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–ª–∏–Ω–Ω–µ–µ 100 —Å–∏–º–≤–æ–ª–æ–≤
3. –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≤–µ–¥–µ–Ω–∏–∏ (–µ–¥–∞, –Ω–∞–ø–∏—Ç–∫–∏, –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞, —É—Å–ª—É–≥–∏, –∞–¥—Ä–µ—Å, —á–∞—Å—ã —Ä–∞–±–æ—Ç—ã)
4. –ò—Å–∫–ª—é—á–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã, –Ω–∞–≤–∏–≥–∞—Ü–∏—é, –º–µ–Ω—é —Å–∞–π—Ç–∞
5. –ò—Å–∫–ª—é—á–∏ —Ç–µ–∫—Å—Ç—ã –æ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
- –ï—Å–ª–∏ –Ω–∞—à–µ–ª –æ–ø–∏—Å–∞–Ω–∏–µ: –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
- –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–µ–ª: –≤–µ—Ä–Ω–∏ "NOT_FOUND"

–û–ü–ò–°–ê–ù–ò–ï:"""
            
            # –í—ã–∑—ã–≤–∞–µ–º GPT —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É HTML –∏ –ø–æ–∏—Å–∫—É –æ–ø–∏—Å–∞–Ω–∏–π –∑–∞–≤–µ–¥–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                max_tokens=500,   # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
                timeout=10        # –ë—ã—Å—Ç—Ä—ã–π —Ç–∞–π–º–∞—É—Ç
            )
            
            result = response.choices[0].message.content.strip()
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if result and result != "NOT_FOUND" and len(result) > 50:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è
                if self._is_venue_description(result):
                    return self._clean_description_text(result)
            
        except Exception as e:
            print(f"GPT-–ø–æ–º–æ—â–Ω–∏–∫ –æ—à–∏–±–∫–∞ –¥–ª—è {place_name}: {e}")
        
        return None
    
    def _create_smart_html_context(self, bold_elem, place_name: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –£–ú–ù–´–ô HTML –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è GPT (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)"""
        from bs4 import BeautifulSoup
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤–æ–∫—Ä—É–≥ –º–µ—Å—Ç–∞
        context_elements = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º–æ –º–µ—Å—Ç–æ
        context_elements.append(str(bold_elem))
        
        # –ò–¥–µ–º –≤–ø–µ—Ä–µ–¥ –Ω–∞ 25 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        current = bold_elem
        for _ in range(25):
            current = current.find_next()
            if not current:
                break
            if hasattr(current, 'get_text') and current.get_text().strip():
                context_elements.append(str(current))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        html_context = '\n'.join(context_elements)
        
        # –û—á–∏—â–∞–µ–º HTML –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è GPT
        soup = BeautifulSoup(html_context, 'html.parser')
        text = soup.get_text()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä (–ø—Ä–∏–º–µ—Ä–Ω–æ 3000 —Ç–æ–∫–µ–Ω–æ–≤)
        if len(text) > 4000:
            text = text[:4000] + "..."
        
        return text
    
    def _create_html_context(self, bold_elem) -> str:
        """–°–æ–∑–¥–∞–µ—Ç HTML –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –º–µ—Å—Ç–∞ –¥–ª—è GPT (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è)"""
        from bs4 import BeautifulSoup
        
        # –ù–∞—Ö–æ–¥–∏–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        parent = bold_elem.parent
        if not parent:
            parent = bold_elem
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ 20 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤–æ–∫—Ä—É–≥ –º–µ—Å—Ç–∞
        context_elements = []
        current = bold_elem
        
        # –ò–¥–µ–º –Ω–∞–∑–∞–¥ –Ω–∞ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for _ in range(5):
            current = current.previous_sibling
            if not current:
                break
            if hasattr(current, 'get_text') and current.get_text().strip():
                context_elements.append(str(current))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º–æ –º–µ—Å—Ç–æ
        context_elements.append(str(bold_elem))
        
        # –ò–¥–µ–º –≤–ø–µ—Ä–µ–¥ –Ω–∞ 15 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        current = bold_elem
        for _ in range(15):
            current = current.next_sibling
            if not current:
                break
            if hasattr(current, 'get_text') and current.get_text().strip():
                context_elements.append(str(current))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        html_context = '\n'.join(context_elements)
        
        # –û—á–∏—â–∞–µ–º HTML –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è GPT
        soup = BeautifulSoup(html_context, 'html.parser')
        return soup.get_text()[:2000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
    
    def _create_search_zones(self, bold_elem) -> list:
        """–°–æ–∑–¥–∞–µ—Ç –∑–æ–Ω—ã –ø–æ–∏—Å–∫–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –¥–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        zones = []
        
        # –ó–û–ù–ê 1: –ë–ª–∏–∂–∞–π—à–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        zone1_elements = []
        
        # 1.1. –°–ª–µ–¥—É—é—â–∏–π div
        next_div = bold_elem.find_next('div')
        if next_div and next_div.get_text().strip():
            zone1_elements.append(next_div)
        
        # 1.2. –°–ª–µ–¥—É—é—â–∏–π p
        next_p = bold_elem.find_next('p')
        if next_p and next_p.get_text().strip():
            zone1_elements.append(next_p)
        
        # 1.3. –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        if bold_elem.parent:
            for elem in bold_elem.parent.find_all(['p', 'div'], recursive=False):
                if elem != bold_elem and elem.get_text().strip():
                    zone1_elements.append(elem)
        
        if zone1_elements:
            zones.append({
                'name': '–ë–ª–∏–∂–∞–π—à–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã',
                'priority': 1,
                'elements': zone1_elements
            })
        
        # –ó–û–ù–ê 2: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        zone2_elements = []
        current = bold_elem
        for _ in range(5):  # –°–ª–µ–¥—É—é—â–∏–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            current = current.find_next()
            if not current:
                break
            if current.name in ['img', 'br', 'hr'] or not current.get_text().strip():
                continue
            if current.name in ['p', 'div', 'span']:
                zone2_elements.append(current)
        
        if zone2_elements:
            zones.append({
                'name': '–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫',
                'priority': 2,
                'elements': zone2_elements
            })
        
        # –ó–û–ù–ê 3: –î–∞–ª—å–Ω–∏–π –ø–æ–∏—Å–∫ (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        zone3_elements = []
        current = bold_elem
        for _ in range(10):  # –°–ª–µ–¥—É—é—â–∏–µ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            current = current.find_next()
            if not current:
                break
            if current.name in ['img', 'br', 'hr'] or not current.get_text().strip():
                continue
            if current.name in ['p', 'div', 'span']:
                zone3_elements.append(current)
        
        if zone3_elements:
            zones.append({
                'name': '–î–∞–ª—å–Ω–∏–π –ø–æ–∏—Å–∫',
                'priority': 3,
                'elements': zone3_elements
            })
        
        return zones
    
    def _is_venue_description(self, text: str) -> bool:
        """–ö–†–ï–ê–¢–ò–í–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–≤–µ–¥–µ–Ω–∏—è"""
        if not text or len(text) < 100:
            return False
        
        text_lower = text.lower()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ä–µ–∫–ª–∞–º–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã (—É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä)
        excluded_phrases = [
            'want the very best stories from bk magazine',
            'sign up for bk weekly',
            'stay up to date on what\'s new and cool',
            'delivered straight to your inbox',
            'bk magazine is a coconuts media publication',
            'copyright ¬© 2020 coconuts media limited',
            'terms of service', 'privacy policy',
            'advertise with us', 'join on facebook',
            'follow on twitter', 'contact us',
            'subscribe', 'newsletter',
            'delivered straight', 'inbox every thursday',
            'want the very best', 'stories from bk',
            'thursday afternoon', 'cool in bangkok'
        ]
        
        for phrase in excluded_phrases:
            if phrase in text_lower:
                return False
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∫–ª–∞–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        if 'bk magazine' in text_lower and len(text) < 200:
            return False
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ–ø–∏—Å–∞–Ω–∏—è –∑–∞–≤–µ–¥–µ–Ω–∏—è
        venue_indicators = [
            # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–≤–µ–¥–µ–Ω–∏–π
            'bar', 'restaurant', 'hotel', 'rooftop', 'venue', 'spot', 'place',
            'cafe', 'coffee', 'bakery', 'deli', 'bistro', 'pub', 'lounge',
            'club', 'nightclub', 'disco', 'karaoke', 'spa', 'salon', 'gym',
            'museum', 'gallery', 'theater', 'cinema', 'mall', 'shop', 'store',
            
            # –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            'floor', 'building', 'view', 'atmosphere', 'ambiance', 'experience',
            'interior', 'design', 'decor', 'style', 'vibe', 'mood', 'feeling',
            'location', 'area', 'district', 'neighborhood', 'street', 'soi',
            
            # –ï–¥–∞ –∏ –Ω–∞–ø–∏—Ç–∫–∏
            'cocktail', 'drink', 'food', 'menu', 'cuisine', 'chef', 'kitchen',
            'pizza', 'pasta', 'italian', 'french', 'japanese', 'thai', 'indian',
            'chinese', 'korean', 'mexican', 'mediterranean', 'fine dining',
            'comfort food', 'brunch', 'breakfast', 'lunch', 'dinner', 'supper',
            'wine', 'beer', 'coffee', 'dessert', 'snack', 'appetizer', 'main',
            
            # –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            'open', 'daily', 'pm', 'am', 'midnight', 'late', 'night', 'dining',
            'hours', 'time', 'schedule', 'available', 'serving', 'offering',
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            'award', 'awarded', 'winner', 'best', 'top', 'famous', 'popular',
            'recommended', 'featured', 'highlighted', 'notable', 'special',
            'unique', 'exclusive', 'premium', 'luxury', 'upscale', 'casual',
            'romantic', 'cozy', 'intimate', 'spacious', 'outdoor', 'indoor',
            'terrace', 'balcony', 'patio', 'garden', 'pool', 'beach'
        ]
        
        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        venue_count = sum(1 for indicator in venue_indicators if indicator in text_lower)
        
        # –ö–†–ï–ê–¢–ò–í–ù–ê–Ø –õ–û–ì–ò–ö–ê:
        # 1. –ï—Å–ª–∏ –µ—Å—Ç—å 3+ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ - —ç—Ç–æ —Ç–æ—á–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è
        if venue_count >= 3:
            return True
        
        # 2. –ï—Å–ª–∏ –µ—Å—Ç—å 2+ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ò –¥–ª–∏–Ω–∞ > 200 - —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è
        if venue_count >= 2 and len(text) > 200:
            return True
        
        # 3. –ï—Å–ª–∏ –µ—Å—Ç—å 1+ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ò –¥–ª–∏–Ω–∞ > 400 - —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è
        if venue_count >= 1 and len(text) > 400:
            return True
        
        # 4. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
        if len(text) >= 100 and len(text) <= 200:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
            key_phrases = [
                'should be no stranger', 'fans of', 'earned the top spot',
                'keeps refining', 'best-in-class', 'located on the',
                'offers panoramic', 'stunning views', 'substandard drinks',
                'not the case', 'sit downstairs', 'upstairs for',
                'can be paired', 'tonic of your choosing'
            ]
            
            for phrase in key_phrases:
                if phrase in text_lower:
                    return True
        
        return False
    
    
    def _is_valid_place_name(self, title: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—Ç–∞"""
        if not title or len(title) < 3:
            return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ —è–≤–Ω–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        service_words = {
            'finalist', 'winner', 'award', 'awards', 'best', 'top', 'new', 'opening', 'opened',
            'photo', 'image', 'credit', 'courtesy', 'source', 'facebook', 'instagram', 'twitter',
            'neighborhood:', 'vibe:', 'price:', 'neighborhood', 'vibe', 'price'
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        title_lower = title.lower()
        for word in service_words:
            if title_lower == word or title_lower.startswith(word + ' '):
                return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ —è–≤–Ω–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        technical_patterns = [
            r'^\d+$',  # –¢–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
            r'^[a-z]{1,2}$',  # –û–¥–Ω–∞-–¥–≤–µ –±—É–∫–≤—ã
            r'^[^a-zA-Z]*$',  # –ë–µ–∑ –±—É–∫–≤
            r'^(photo|image|credit|courtesy)',  # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
        ]
        
        for pattern in technical_patterns:
            if re.match(pattern, title_lower):
                return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π (—Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ)
        technical_indicators = [
            'open daily', 'open monday', 'open tuesday', 'open wednesday',
            'open thursday', 'open friday', 'open saturday', 'open sunday',
            'phone', 'tel', 'address', 'location', 'hours', 'closed',
            'road.', 'soi.', 'floor.', 'pm.', 'am.'
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –∞ –Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
        for indicator in technical_indicators:
            if indicator in title_lower:
                return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–≤–µ—Ä–æ—è—Ç–Ω–æ –∞–¥—Ä–µ—Å–∞ –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è)
        if len(title) > 50:  # –£–º–µ–Ω—å—à–∏–ª–∏ —Å 200 –¥–æ 50
            return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å –Ω–µ–≤–∏–¥–∏–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
        if title.startswith('‚Äã') or title.endswith('‚Äã'):
            return False
        
        return True
    
    
    def _is_service_text(self, text: str) -> bool:
        """–£–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç —Å–ª—É–∂–µ–±–Ω—ã–º"""
        if not text or len(text) < 50:
            return True
        
        text_lower = text.lower()
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–≤–µ–¥–µ–Ω–∏—è - —ç—Ç–æ –Ω–µ —Å–ª—É–∂–µ–±–Ω—ã–π —Ç–µ–∫—Å—Ç
        venue_indicators = [
            'bar', 'restaurant', 'hotel', 'rooftop', 'venue', 'spot', 'place',
            'floor', 'building', 'view', 'cocktail', 'drink', 'food', 'menu',
            'open', 'daily', 'pm', 'am', 'midnight', 'late', 'night'
        ]
        
        venue_count = sum(1 for indicator in venue_indicators if indicator in text_lower)
        if venue_count >= 2:  # –ï—Å–ª–∏ –µ—Å—Ç—å 2+ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –∑–∞–≤–µ–¥–µ–Ω–∏—è - —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–ª—É–∂–µ–±–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–≤–æ–¥–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤
        service_indicators = [
            'bangkok likes to party',
            'this year, we\'ve got',
            'annual bad awards',
            'media junket',
            'promotional vehicle',
            'opening in just',
            'crack this list',
            'gleaming high rises'
        ]
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        if len(text) < 200:
            for indicator in service_indicators:
                if indicator in text_lower:
                    return True
        
        return False
    
    
    def _clean_description_text(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç –∞–¥—Ä–µ—Å–æ–≤ –∏ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"""
        # –£–¥–∞–ª—è–µ–º –∞–¥—Ä–µ—Å–∞
        text = re.sub(r'\d+/F.*?(?=\s|$)', '', text)
        text = re.sub(r'\d+.*?Soi.*?(?=\s|$)', '', text)
        text = re.sub(r'\d+.*?Sukhumvit.*?(?=\s|$)', '', text)
        text = re.sub(r'\d+.*?Sathorn.*?(?=\s|$)', '', text)
        text = re.sub(r'\d+.*?Wireless.*?(?=\s|$)', '', text)
        
        # –£–¥–∞–ª—è–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω—ã
        text = re.sub(r'0[0-9-\\s]{8,}', '', text)
        
        # –£–¥–∞–ª—è–µ–º —á–∞—Å—ã —Ä–∞–±–æ—Ç—ã
        text = re.sub(r'Open.*?(?=\s|$)', '', text)
        text = re.sub(r'Daily.*?(?=\s|$)', '', text)
        
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        text = re.sub(r'\\s+', ' ', text).strip()
        
        return text if len(text) > 20 else ""
    
    
    def _remove_duplicates(self, places: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        seen = set()
        unique_places = []
        
        for place in places:
            name_key = place['title'].lower().strip()
            if name_key not in seen:
                seen.add(name_key)
                unique_places.append(place)
        
        return unique_places

    def parse_catalog_page(self, catalog_url: str, max_pages: int = None) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞ BK Magazine –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏
        
        Args:
            catalog_url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, search-news?type=restaurant)
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (None = –≤—Å–µ)
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–∞—Ç—å—è—Ö
        """
        all_articles = []
        page = 0
        
        while True:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if page == 0:
                url = catalog_url
            else:
                separator = '&' if '?' in catalog_url else '?'
                url = f"{catalog_url}{separator}page={page}"
            
            print(f"üìÑ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {url}")
            
            try:
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # –ò—â–µ–º H5 –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤)
                h5_tags = soup.find_all('h5')
                
                if not h5_tags:
                    print(f"   ‚ùå –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} –ø—É—Å—Ç–∞—è - –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                    break
                
                page_articles = []
                
                for h5 in h5_tags:
                    restaurant_name = h5.get_text().strip()
                    
                    # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç—å—é
                    article_link = None
                    parent = None
                    
                    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Å–∞–º–æ–º H5
                    h5_link = h5.find('a')
                    if h5_link and h5_link.get('href'):
                        article_link = h5_link.get('href')
                    else:
                        # –ò—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º div
                        parent = h5.parent
                        if parent:
                            parent_link = parent.find('a', href=True)
                            if parent_link and parent_link.get('href').startswith('/restaurants/'):
                                article_link = parent_link.get('href')
                    
                    if article_link:
                        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –≤ –∞–±—Å–æ–ª—é—Ç–Ω—É—é
                        if article_link.startswith('/'):
                            article_link = f"https://bk.asia-city.com{article_link}"
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ div
                        description = ""
                        if parent:
                            # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤ —Ç–µ–∫—Å—Ç–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ div
                            parent_text = parent.get_text()
                            lines = parent_text.split('\n')
                            for line in lines:
                                line = line.strip()
                                if line and line != restaurant_name and not line.startswith('Restaurant') and not 'ago' in line:
                                    description = line
                                    break
                        
                        page_articles.append({
                            'title': restaurant_name,
                            'article_url': article_link,
                            'description': description,
                            'category': 'Restaurant'
                        })
                
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(page_articles)} —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                all_articles.extend(page_articles)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
                if max_pages and page >= max_pages - 1:
                    print(f"   üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
                    break
                
                page += 1
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                break
        
        print(f"\\nüìä –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û –°–¢–ê–¢–ï–ô: {len(all_articles)}")
        return all_articles

    def parse_catalog_articles(self, catalog_url: str, limit: int = None, max_pages: int = None) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏—Ç –∫–∞—Ç–∞–ª–æ–≥ –∏ –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –≤ –Ω–µ–º
        
        Args:
            catalog_url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
            limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–∞—Ç–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–µ—Å—Ç –∏–∑ –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –∫–∞—Ç–∞–ª–æ–≥–∞
        """
        print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞: {catalog_url}")
        if max_pages:
            print(f"üìÑ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü: {max_pages}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞
        articles = self.parse_catalog_page(catalog_url, max_pages=max_pages)
        print(f"üì∞ –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}")
        
        if limit:
            articles = articles[:limit]
            print(f"üìù –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ: {len(articles)} —Å—Ç–∞—Ç–µ–π")
        
        all_places = []
        
        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é —Å—Ç–∞—Ç—å—é
        for i, article in enumerate(articles, 1):
            print(f"\\nüìñ –°—Ç–∞—Ç—å—è {i}/{len(articles)}: {article['title']}")
            
            try:
                places = self.parse_article_page(article['article_url'])
                print(f"   –ù–∞–π–¥–µ–Ω–æ –º–µ—Å—Ç: {len(places)}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ –∫ –∫–∞–∂–¥–æ–º—É –º–µ—Å—Ç—É
                for place in places:
                    place['article_title'] = article['title']
                    place['article_url'] = article['article_url']
                
                all_places.extend(places)
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç–∞—Ç—å–∏: {e}")
                continue
        
        print(f"\\nüìä –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û –ú–ï–°–¢: {len(all_places)}")
        return all_places


def test_parser():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞"""
    adapter = BKMagazineAdapter()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    test_url = 'https://bk.asia-city.com/nightlife/article/bangkoks-best-rooftop-bars'
    
    print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä BK Magazine –Ω–∞: {test_url}")
    places = adapter.parse_article_page(test_url)
    
    print(f"\\n–ù–∞–π–¥–µ–Ω–æ –º–µ—Å—Ç: {len(places)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ–ø–∏—Å–∞–Ω–∏—è–º
    places_with_desc = [p for p in places if p['teaser']]
    print(f"–ú–µ—Å—Ç —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏: {len(places_with_desc)}/{len(places)}")
    
    for i, place in enumerate(places[:5], 1):
        print(f"\\n{i}. {place['title']}")
        print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {place['teaser'] or '–ù–µ—Ç'}")


if __name__ == "__main__":
    test_parser()
