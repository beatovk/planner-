"""
QueryBuilder - —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–ª–æ—Ç–æ–≤.
"""

import re
import time
import logging
from typing import List, Dict, Any, Optional, Set, Tuple
from pathlib import Path
import yaml

from apps.places.schemas.slots import (
    Slot, SlotType, SlotMatch, SlotterResult, SlotterConfig,
    QueryToken, SynonymEntry, SlotterMetrics,
    create_slot, create_slot_match, create_slotter_result,
    create_query_token, create_synonym_entry
)

logger = logging.getLogger(__name__)


class QueryBuilder:
    """–°—Ç—Ä–æ–∏—Ç–µ–ª—å –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Å–ª–æ—Ç–æ–≤."""
    
    def __init__(self, config: SlotterConfig = None):
        self.config = config or SlotterConfig()
        self.synonyms: Dict[str, SynonymEntry] = {}
        self.metrics = SlotterMetrics()
        self._load_synonyms()
    
    def _load_synonyms(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –∏–∑ config/synonyms.yml."""
        try:
            config_path = Path("config/synonyms.yml")
            if not config_path.exists():
                logger.error("synonyms.yml not found")
                return
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            for slot_data in config.get('slots', []):
                try:
                    entry = create_synonym_entry(
                        type=SlotType(slot_data['type']),
                        canonical=slot_data['canonical'],
                        synonyms=slot_data['synonyms'],
                        expands_to_tags=slot_data['expands_to_tags'],
                        denylist=slot_data.get('denylist')
                    )
                    
                    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º
                    for synonym in entry.synonyms:
                        self.synonyms[synonym.lower()] = entry
                    
                    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø–æ canonical
                    self.synonyms[entry.canonical.lower()] = entry
                    
                except Exception as e:
                    logger.warning(f"Failed to load slot {slot_data.get('canonical', 'unknown')}: {e}")
            
            logger.info(f"Loaded {len(self.synonyms)} synonym entries")
            
        except Exception as e:
            logger.error(f"Failed to load synonyms: {e}")
            raise
    
    def build_slots(self, query: str) -> SlotterResult:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ª–æ—Ç—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞."""
        start_time = time.time()
        
        try:
            logger.debug(f"Building slots for query: '{query}'")
            
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
            tokens = self._tokenize_query(query)
            logger.debug(f"Tokenized query into {len(tokens)} tokens: {[t.text for t in tokens]}")
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ª–æ—Ç–æ–≤
            slot_matches = self._extract_slots(tokens)
            logger.debug(f"Extracted {len(slot_matches)} slot matches")
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ confidence –∏ –ø–æ–∑–∏—Ü–∏–∏
            slot_matches.sort(key=lambda x: (-x.confidence, x.position))
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ—Ç–æ–≤
            slot_matches = slot_matches[:self.config.max_slots]
            logger.debug(f"Limited to {len(slot_matches)} slots after max_slots filter")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ—Ç–æ–≤
            slots = []
            for match in slot_matches:
                slot = self._create_slot_from_match(match)
                slots.append(slot)
                logger.debug(f"Created slot: {slot.type}:{slot.canonical} (confidence: {slot.confidence:.2f})")

            # –ö–æ–Ω—Ç–µ–∫—Å—Ç: –µ—Å–ª–∏ —Å—Ä–µ–¥–∏ —Å–ª–æ—Ç–æ–≤ –µ—Å—Ç—å –±–ª—é–¥–æ ‚Äî –ø–æ–º–µ—á–∞–µ–º –≤—Å–µ–º has_dish=True
            try:
                has_dish = any(s.type == SlotType.DISH for s in slots)
                if has_dish:
                    for s in slots:
                        # Slot.context –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ create_slot
                        s.context["has_dish"] = True
            except Exception:
                pass
            
            # Fallback –µ—Å–ª–∏ —Å–ª–æ—Ç–æ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
            fallback_used = False
            fallback_reason = None
            
            if len(slots) < 3 and self.config.enable_fallback:
                logger.debug(f"Applying fallback strategies for {3 - len(slots)} missing slots")
                fallback_slots = self._apply_fallback_strategies(query, slots)
                slots.extend(fallback_slots)
                fallback_used = True
                fallback_reason = f"Added {len(fallback_slots)} fallback slots"
                logger.debug(f"Added {len(fallback_slots)} fallback slots: {[s.canonical for s in fallback_slots]}")
            
            processing_time = (time.time() - start_time) * 1000
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            self._update_metrics(len(slots), fallback_used, processing_time)
            
            logger.info(f"Built {len(slots)} slots for query '{query}' in {processing_time:.2f}ms")
            
            return create_slotter_result(
                slots=slots,
                fallback_used=fallback_used,
                fallback_reason=fallback_reason,
                processing_time_ms=processing_time,
                debug_info={
                    'tokens': [t.text for t in tokens],
                    'matches': len(slot_matches),
                    'fallback_slots': len(slots) - len(slot_matches),
                    'slot_types': [s.type.value for s in slots],
                    'confidences': [s.confidence for s in slots]
                }
            )
            
        except Exception as e:
            logger.error(f"Failed to build slots for query '{query}': {e}")
            return create_slotter_result(
                slots=[],
                fallback_used=False,
                processing_time_ms=(time.time() - start_time) * 1000,
                debug_info={'error': str(e)}
            )
    
    def _tokenize_query(self, query: str) -> List[QueryToken]:
        """–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ñ—Ä–∞–∑—ã, –º–Ω–æ–≥–æ—Å–ª–æ–≤–Ω—ã–µ –∏ –æ–¥–Ω–æ—Å–ª–æ–≤–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã."""
        tokens = []
        query_lower = query.lower().strip()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words = re.findall(r'\b\w+\b', query_lower)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–æ–∫–µ–Ω—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã
        for i, word in enumerate(words):
            # –û–¥–Ω–æ—Å–ª–æ–≤–Ω—ã–π —Ç–æ–∫–µ–Ω
            tokens.append(create_query_token(
                text=word,
                position=i,
                length=1,
                is_unigram=True
            ))
            
            # –ú–Ω–æ–≥–æ—Å–ª–æ–≤–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (2-3 —Å–ª–æ–≤–∞)
            for length in [2, 3]:
                if i + length <= len(words):
                    phrase = ' '.join(words[i:i+length])
                    tokens.append(create_query_token(
                        text=phrase,
                        position=i,
                        length=length,
                        is_multiword=True
                    ))
        
        # –§—Ä–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã (4+ —Å–ª–æ–≤)
        for length in range(4, len(words) + 1):
            for i in range(len(words) - length + 1):
                phrase = ' '.join(words[i:i+length])
                tokens.append(create_query_token(
                    text=phrase,
                    position=i,
                    length=length,
                    is_phrase=True
                ))
        
        return tokens
    
    def _extract_slots(self, tokens: List[QueryToken]) -> List[SlotMatch]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ª–æ—Ç—ã –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤."""
        matches = []
        used_positions = set()
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è: phrase > multiword > unigram
        for token in sorted(tokens, key=lambda t: (-t.length, t.position)):
            if token.position in used_positions:
                continue
            
            # –ü–æ–∏—Å–∫ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if token.text in self.synonyms:
                entry = self.synonyms[token.text]
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ denylist
                if entry.is_denied(token.text):
                    continue
                
                # –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—á–∞
                match = self._create_slot_match(entry, token, "exact")
                matches.append(match)
                used_positions.update(range(token.position, token.position + token.length))
                continue
            
            # Fuzzy matching –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
            if self.config.enable_fuzzy:
                fuzzy_match = self._find_fuzzy_match(token)
                if fuzzy_match:
                    matches.append(fuzzy_match)
                    used_positions.update(range(token.position, token.position + token.length))
        
        return matches
    
    def _find_fuzzy_match(self, token: QueryToken) -> Optional[SlotMatch]:
        """–ù–∞—Ö–æ–¥–∏—Ç fuzzy —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è —Ç–æ–∫–µ–Ω–∞."""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è fuzzy matching
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pg_trgm/unaccent
        
        best_match = None
        best_score = 0.0
        
        for synonym, entry in self.synonyms.items():
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ denylist
            if entry.is_denied(token.text):
                continue
            
            # –ü—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å—Ö–æ–∂–µ—Å—Ç–∏
            score = self._calculate_similarity(token.text, synonym)
            
            if score >= self.config.fuzzy_threshold and score > best_score:
                best_score = score
                best_match = self._create_slot_match(entry, token, "fuzzy", score)
        
        return best_match
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏."""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Jaccard similarity
        set1 = set(text1.lower())
        set2 = set(text2.lower())
        
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        
        return intersection / union if union > 0 else 0.0
    
    def _create_slot_match(self, entry: SynonymEntry, token: QueryToken, match_type: str, confidence: float = None) -> SlotMatch:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Ç—á–∏–Ω–≥–∞ —Å–ª–æ—Ç–∞."""
        if confidence is None:
            # –ë–∞–∑–æ–≤—ã–π confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –º–∞—Ç—á–∞
            confidence_map = {
                "exact": 1.0,
                "phrase": 0.9,
                "multiword": 0.8,
                "unigram": 0.7,
                "fuzzy": 0.6
            }
            confidence = confidence_map.get(match_type, 0.5)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ—Ç
        slot = create_slot(
            type=entry.type,
            canonical=entry.canonical,
            label=entry.canonical.replace('_', ' ').title(),
            confidence=confidence,
            filters={'expands_to_tags': entry.expands_to_tags},
            matched_text=token.text,
            reason=f"matched {entry.type}:{entry.canonical}"
        )
        
        return create_slot_match(
            slot=slot,
            matched_synonym=token.text,
            match_type=match_type,
            confidence=confidence,
            position=token.position
        )
    
    def _create_slot_from_match(self, match: SlotMatch) -> Slot:
        """–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–∞—Ç—á–∏–Ω–≥–∞."""
        return match.slot
    
    def _apply_fallback_strategies(self, query: str, existing_slots: List[Slot]) -> List[Slot]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ—Ç–æ–≤."""
        high_conf_slots = [slot for slot in existing_slots if slot.confidence >= 0.8]
        if high_conf_slots:
            token_count = len(self._tokenize_query(query))
            # –ù–µ –ø–æ–¥–º–µ—à–∏–≤–∞–µ–º –æ–±—â–∏–π fallback, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–ª –æ–¥–∏–Ω –∏–ª–∏ –¥–≤–∞ —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–∞
            if token_count <= 5:
                return []

        fallback_slots = []
        
        for strategy in self.config.fallback_strategies:
            if strategy == "signals:editorial":
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ editorial signals
                slot = self._create_editorial_fallback_slot(query)
                if slot:
                    fallback_slots.append(slot)
            
            elif strategy == "co-occurrence":
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ co-occurrence
                slot = self._create_cooccurrence_fallback_slot(query)
                if slot:
                    fallback_slots.append(slot)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ fallback —Å–ª–æ—Ç–æ–≤
            if len(fallback_slots) >= 3 - len(existing_slots):
                break
        
        return fallback_slots
    
    def _create_editorial_fallback_slot(self, query: str) -> Optional[Slot]:
        """–°–æ–∑–¥–∞–µ—Ç fallback —Å–ª–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ editorial signals."""
        query_lower = query.lower()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –æ–ø—ã—Ç–∞
        if any(word in query_lower for word in ['date', 'dating', 'romantic', 'anniversary', 'proposal']):
            return create_slot(
                type=SlotType.VIBE,
                canonical="romantic",
                label="Romantic",
                confidence=0.3,
                filters={'expands_to_tags': ['vibe:romantic', 'scenario:date']},
                matched_text=query,
                reason="fallback:editorial_romantic"
            )
        if any(word in query_lower for word in ['food', 'eat', 'restaurant', 'dinner', 'lunch']):
            return create_slot(
                type=SlotType.CUISINE,
                canonical="thai",
                label="Thai Cuisine",
                confidence=0.3,
                filters={'expands_to_tags': ['cuisine:thai']},
                matched_text=query,
                reason="fallback:editorial_food"
            )
        elif any(word in query_lower for word in ['drink', 'wine', 'coffee', 'tea', 'bar']):
            return create_slot(
                type=SlotType.DRINK,
                canonical="specialty_coffee",
                label="Specialty Coffee",
                confidence=0.3,
                filters={'expands_to_tags': ['drink:specialty_coffee']},
                matched_text=query,
                reason="fallback:editorial_drink"
            )
        elif any(word in query_lower for word in ['view', 'rooftop', 'skyline', 'scenic']):
            return create_slot(
                type=SlotType.EXPERIENCE,
                canonical="rooftop",
                label="Rooftop Experience",
                confidence=0.3,
                filters={'expands_to_tags': ['experience:rooftop']},
                matched_text=query,
                reason="fallback:editorial_view"
            )
        else:
            return create_slot(
                type=SlotType.EXPERIENCE,
                canonical="live_music",
                label="Live Music",
                confidence=0.3,
                filters={'expands_to_tags': ['experience:live_music']},
                matched_text=query,
                reason="fallback:editorial_general"
            )
    
    def _create_cooccurrence_fallback_slot(self, query: str) -> Optional[Slot]:
        """–°–æ–∑–¥–∞–µ—Ç fallback —Å–ª–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ co-occurrence."""
        query_lower = query.lower()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —Å–ª–æ—Ç–∞
        if any(word in query_lower for word in ['chill', 'relax', 'calm', 'quiet']):
            return create_slot(
                type=SlotType.VIBE,
                canonical="chill",
                label="Chill Vibe",
                confidence=0.3,
                filters={'expands_to_tags': ['vibe:chill']},
                matched_text=query,
                reason="fallback:co-occurrence_chill"
            )
        elif any(word in query_lower for word in ['romantic', 'date', 'couple', 'intimate']):
            return create_slot(
                type=SlotType.VIBE,
                canonical="romantic",
                label="Romantic Vibe",
                confidence=0.3,
                filters={'expands_to_tags': ['vibe:romantic']},
                matched_text=query,
                reason="fallback:co-occurrence_romantic"
            )
        elif any(word in query_lower for word in ['art', 'gallery', 'museum', 'culture']):
            return create_slot(
                type=SlotType.EXPERIENCE,
                canonical="gallery",
                label="Gallery Experience",
                confidence=0.3,
                filters={'expands_to_tags': ['experience:gallery']},
                matched_text=query,
                reason="fallback:co-occurrence_art"
            )
        elif any(word in query_lower for word in ['date', 'dating', 'romantic', 'anniversary', 'proposal']):
            return create_slot(
                type=SlotType.VIBE,
                canonical="romantic",
                label="Romantic Vibe",
                confidence=0.3,
                filters={'expands_to_tags': ['vibe:romantic', 'scenario:date']},
                matched_text=query,
                reason="fallback:co-occurrence_romantic"
            )
        elif any(word in query_lower for word in ['music', 'live', 'band', 'concert']):
            return create_slot(
                type=SlotType.EXPERIENCE,
                canonical="live_music",
                label="Live Music",
                confidence=0.3,
                filters={'expands_to_tags': ['experience:live_music']},
                matched_text=query,
                reason="fallback:co-occurrence_music"
            )
        
        return None
    
    def _update_metrics(self, slots_count: int, fallback_used: bool, processing_time: float) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–ª–æ—Ç—Ç–µ—Ä–∞."""
        self.metrics.total_queries += 1
        
        if slots_count > 0:
            self.metrics.successful_matches += 1
        
        if fallback_used:
            self.metrics.fallback_used += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        self.metrics.avg_processing_time_ms = (
            (self.metrics.avg_processing_time_ms * (self.metrics.total_queries - 1) + processing_time) 
            / self.metrics.total_queries
        )
        
        self.metrics.avg_slots_per_query = (
            (self.metrics.avg_slots_per_query * (self.metrics.total_queries - 1) + slots_count) 
            / self.metrics.total_queries
        )
    
    def get_metrics(self) -> SlotterMetrics:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–ª–æ—Ç—Ç–µ—Ä–∞."""
        return self.metrics
    
    def reset_metrics(self) -> None:
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏."""
        self.metrics = SlotterMetrics()


# –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è QueryBuilder
def create_query_builder(config: SlotterConfig = None) -> QueryBuilder:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä QueryBuilder."""
    return QueryBuilder(config)


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å QueryBuilder
def build_slots_from_query(query: str, config: SlotterConfig = None) -> SlotterResult:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–ª–æ—Ç–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞."""
    builder = create_query_builder(config)
    return builder.build_slots(query)


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ QueryBuilder
    builder = create_query_builder()
    
    test_queries = [
        "today i wanna chill, eat tom yum and go on the rooftop",
        "gallery, tea, sushi",
        "romantic dinner with wine",
        "thai food in thonglor"
    ]
    
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ QueryBuilder...")
    print()
    
    for query in test_queries:
        print(f"–ó–∞–ø—Ä–æ—Å: '{query}'")
        result = builder.build_slots(query)
        
        print(f"   - –°–ª–æ—Ç–æ–≤: {len(result.slots)}")
        print(f"   - Fallback: {'‚úÖ' if result.fallback_used else '‚ùå'}")
        print(f"   - –í—Ä–µ–º—è: {result.processing_time_ms:.2f}ms")
        
        for slot in result.slots:
            print(f"   - {slot.type}:{slot.canonical} (confidence: {slot.confidence:.2f})")
        
        print()
    
    print("üéØ QueryBuilder –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
