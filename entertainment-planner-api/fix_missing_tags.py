#!/usr/bin/env python3
"""
–í—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è 1220 –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ç–µ–≥–æ–≤
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–≥–∏–∫—É GPT Normalizer –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–µ–π –≤ —Å—Ç–∞—Ç—É—Å–µ 'published'
"""

import os
import sys
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from apps.core.db import SessionLocal
from apps.places.models import Place
from apps.places.workers.gpt_client import GPTClient

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TagsFixer:
    """–í—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ç–µ–≥–æ–≤"""
    
    def __init__(self, batch_size: int = 10, api_key: str = None):
        self.batch_size = batch_size
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        
        self.gpt_client = GPTClient(self.api_key)
        self.processed_count = 0
        self.error_count = 0
        self.success_count = 0
        
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ç–µ–≥–æ–≤...")
        
        try:
            self._process_batches()
            self._log_results()
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise
    
    def _process_batches(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π –±–∞—Ç—á–∞–º–∏"""
        while True:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
            db = SessionLocal()
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏ published –±–µ–∑ —Ç–µ–≥–æ–≤
                places = (
                    db.query(Place)
                    .filter(
                        Place.processing_status == 'published',
                        (Place.tags_csv.is_(None) | (Place.tags_csv == ''))
                    )
                    .limit(self.batch_size)
                    .all()
                )
                
                if not places:
                    logger.info("‚úÖ –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                    break
                
                logger.info(f"üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á –∏–∑ {len(places)} –∑–∞–ø–∏—Å–µ–π")
                
                for place in places:
                    try:
                        self._process_place(place, db)
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ—Å—Ç–∞ {place.id}: {e}")
                        self.error_count += 1
                        self._mark_as_error(place, str(e), db)
                
                db.commit()
                self.processed_count += len(places)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}")
                db.rollback()
            finally:
                db.close()
    
    def _process_place(self, place: Place, db):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ —á–µ—Ä–µ–∑ GPT"""
        logger.info(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–µ—Å—Ç–æ: {place.name}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è
        if not place.description_full or not str(place.description_full).strip():
            logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π description_full –¥–ª—è {place.name}")
            return
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º payload –¥–ª—è GPT
        payload = self._create_payload(place)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT
        response = self._send_to_gpt(payload)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
        self._update_place(place, response, db)
        
        self.success_count += 1
        logger.info(f"‚úÖ –ú–µ—Å—Ç–æ {place.name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    
    def _create_payload(self, place: Place) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ payload –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ GPT"""
        return {
            "id": place.id,
            "name": place.name,
            "description_full": place.description_full,
            "summary": place.summary,
            "tags_csv": place.tags_csv,
            "address": place.address,
            "hours_json": place.hours_json,
            "hours_text": self._extract_hours_text(place),
            "gmaps_url": place.gmaps_url,
            "lat": place.lat,
            "lng": place.lng
        }
    
    def _extract_hours_text(self, place: Place) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π"""
        if place.hours_json:
            return place.hours_json
        
        # –ò—â–µ–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
        if place.description_full:
            import re
            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —á–∞—Å–æ–≤
            hours_pattern = r'Open[^.]*|Closed[^.]*|Mon[^.]*|Tue[^.]*|Wed[^.]*|Thu[^.]*|Fri[^.]*|Sat[^.]*|Sun[^.]*'
            match = re.search(hours_pattern, place.description_full)
            if match:
                return match.group(0)
        
        return None
    
    def _send_to_gpt(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ GPT API"""
        return self.gpt_client.normalize_place_data(payload)
    
    def _update_place(self, place: Place, response: Dict[str, Any], db):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–∞ GPT"""
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø–æ–ª—è, –Ω–µ –º–µ–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å
        
        # merge tags (lower, dedupe)
        new_tags = [t.strip().lower() for t in (response.get('tags') or []) if t and t.strip()]
        old_tags = [t.strip().lower() for t in (place.tags_csv or '').split(',') if t.strip()]
        merged = []
        seen = set()
        for t in old_tags + new_tags:
            if t and t not in seen:
                seen.add(t)
                merged.append(t)
        place.tags_csv = ','.join(merged) if merged else None

        # category –∏–∑ –ø–µ—Ä–≤—ã—Ö category:* —Ç–µ–≥–æ–≤
        cat = next((t.split(':',1)[1] for t in merged if t.startswith('category:') and ':' in t), None)
        if cat:
            place.category = cat

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º signals –∫–∞–∫ JSON –∏–∑ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã signals
        signals_data = response.get('signals') or {}
        if isinstance(signals_data, dict):
            place.signals = signals_data
        else:
            # fallback –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ interest_signals
            interest_signals = response.get('interest_signals') or {}
            if isinstance(interest_signals, dict):
                place.signals = interest_signals
            elif isinstance(interest_signals, list):
                place.signals = {k: True for k in interest_signals}
            else:
                place.signals = {}
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å bitset/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        try:
            from apps.places.services.bitset_service import BitsetService
            from apps.places.schemas.vibes import VibesOntology
            import yaml
            
            with open(os.path.join(os.getcwd(), "config", "vibes.yml"), "r", encoding="utf-8") as f:
                vibescfg = yaml.safe_load(f)
            ontology = VibesOntology.from_yaml(vibescfg)
            bs = BitsetService(ontology)
            tags = [t.strip() for t in (place.tags_csv or '').split(',') if t.strip()]
            place.tag_bitset = bs.tags_to_bitset(tags)
        except Exception as e:
            logger.warning(f"Bitset recompute skipped: {e}")

        # –ù–ï –º–µ–Ω—è–µ–º processing_status - –æ—Å—Ç–∞–≤–ª—è–µ–º 'published'
        place.updated_at = datetime.now(timezone.utc)
        db.flush()
    
    def _mark_as_error(self, place: Place, error_msg: str, db):
        """–ü–æ–º–µ—á–∞–µ–º –∑–∞–ø–∏—Å—å –∫–∞–∫ –æ—à–∏–±–æ—á–Ω—É—é"""
        place.processing_status = 'error'
        place.last_error = error_msg
        place.updated_at = datetime.now(timezone.utc)
        db.flush()
    
    def _log_results(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–±–æ—Ç—ã"""
        logger.info("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤:")
        logger.info(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.processed_count}")
        logger.info(f"  –£—Å–ø–µ—à–Ω–æ: {self.success_count}")
        logger.info(f"  –û—à–∏–±–æ–∫: {self.error_count}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ç–µ–≥–æ–≤')
    parser.add_argument('--batch-size', type=int, default=10, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    parser.add_argument('--api-key', type=str, help='OpenAI API –∫–ª—é—á')
    parser.add_argument('--verbose', '-v', action='store_true', help='–ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Set API key
    if args.api_key:
        os.environ['OPENAI_API_KEY'] = args.api_key
    
    try:
        fixer = TagsFixer(
            batch_size=args.batch_size,
            api_key=args.api_key
        )
        
        print("ü§ñ –ó–∞–ø—É—Å–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ç–µ–≥–æ–≤...")
        print(f"üìä –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {args.batch_size}")
        print(f"üîë API –∫–ª—é—á: {'—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if os.getenv('OPENAI_API_KEY') else '–ù–ï –ù–ê–ô–î–ï–ù'}")
        print("-" * 50)
        
        fixer.run()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
