#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–µ—Å—Ç –∏–∑ —Ç—Ä–µ—Ö –Ω–æ–≤—ã—Ö CSV —Ñ–∞–π–ª–æ–≤:
- + Bangkokmalls.csv
- +Bangkok_Food___Batch_08__next_100__6__sentences__no_photos_.csv
- +bkk_food_batch_11_100_no_photos_min6_v2.csv
"""

import os
import sys
import csv
import psycopg
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv(Path(__file__).parent / '.env')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º URL –¥–ª—è psycopg
db_url = os.getenv("DATABASE_URL", "postgresql://ep:ep@localhost:5432/ep")
if "+psycopg" in db_url:
    db_url = db_url.replace("+psycopg", "")
DB_URL = db_url

# –ü—É—Ç–∏ –∫ CSV —Ñ–∞–π–ª–∞–º
CSV_FILES = [
    {
        'path': Path("/Users/user/entertainment planner/docs/places.csv/+ Bangkokmalls.csv"),
        'source': 'bangkok_malls',
        'category': 'mall'
    },
    {
        'path': Path("/Users/user/entertainment planner/docs/places.csv/+Bangkok_Food___Batch_08__next_100__6__sentences__no_photos_.csv"),
        'source': 'bangkok_food_batch_08',
        'category': 'restaurant'
    },
    {
        'path': Path("/Users/user/entertainment planner/docs/places.csv/+bkk_food_batch_11_100_no_photos_min6_v2.csv"),
        'source': 'bkk_food_batch_11',
        'category': 'restaurant'
    }
]

def import_csv_batch(csv_file_info):
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Å—Ç–∞ –∏–∑ –æ–¥–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞."""
    
    csv_path = csv_file_info['path']
    source = csv_file_info['source']
    category = csv_file_info['category']
    
    print(f"üìÅ –ò–º–ø–æ—Ä—Ç –∏–∑ {csv_path.name}...")
    
    if not csv_path.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")
        return 0, 0
    
    conn = None
    try:
        conn = psycopg.connect(DB_URL)
        cursor = conn.cursor()
        
        imported_count = 0
        skipped_count = 0
        
        with open(csv_path, mode='r', encoding='utf-8-sig') as file:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ
            first_line = file.readline()
            file.seek(0)
            
            if ';' in first_line:
                reader = csv.DictReader(file, delimiter=';')
            else:
                reader = csv.DictReader(file, delimiter=',')
            
            for row in reader:
                name = row.get('name', '').strip()
                description_full = row.get('description_full', '').strip()
                
                if not name or not description_full:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (–ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ): {name}")
                    skipped_count += 1
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –º–µ—Å—Ç–æ —Å —Ç–∞–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º
                cursor.execute("SELECT id FROM places WHERE name = %s", (name,))
                if cursor.fetchone():
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç): {name}")
                    skipped_count += 1
                    continue
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –º–µ—Å—Ç–æ
                cursor.execute('''
                INSERT INTO places (
                    name, category, description_full, source, 
                    processing_status, scraped_at, updated_at
                ) VALUES (
                    %s, %s, %s, %s,
                    %s, %s, %s
                )
                ''', (
                    name,
                    category,
                    description_full,
                    source,
                    'new',
                    datetime.now(),
                    datetime.now()
                ))
                
                print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {name}")
                imported_count += 1
        
        # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        conn.commit()
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã {csv_path.name}:")
        print(f"   ‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {imported_count} –º–µ—Å—Ç")
        print(f"   ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count} –º–µ—Å—Ç")
        
        return imported_count, skipped_count
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ {csv_path.name}: {e}")
        if conn:
            conn.rollback()
        return 0, 0
    finally:
        if conn:
            conn.close()

def import_all_batches():
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ CSV —Ñ–∞–π–ª—ã."""
    
    print("üöÄ –ò–ú–ü–û–†–¢ –ù–û–í–´–• –ü–ê–†–¢–ò–ô –ú–ï–°–¢")
    print("=" * 50)
    
    total_imported = 0
    total_skipped = 0
    
    for csv_file_info in CSV_FILES:
        imported, skipped = import_csv_batch(csv_file_info)
        total_imported += imported
        total_skipped += skipped
        print()
    
    print("üéâ –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"‚úÖ –í—Å–µ–≥–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {total_imported} –º–µ—Å—Ç")
    print(f"‚ö†Ô∏è –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {total_skipped} –º–µ—Å—Ç")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    conn = None
    try:
        conn = psycopg.connect(DB_URL)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT source, COUNT(*) FROM places
            WHERE source IN ('bangkok_malls', 'bangkok_food_batch_08', 'bkk_food_batch_11')
            GROUP BY source ORDER BY COUNT(*) DESC
        ''')
        source_stats = cursor.fetchall()
        
        print(f"\nüìÇ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ò–°–¢–û–ß–ù–ò–ö–ê–ú:")
        for source, count in source_stats:
            print(f"   {source}: {count} –º–µ—Å—Ç")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    import_all_batches()
