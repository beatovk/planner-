#!/usr/bin/env python3
"""
–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–∫—Ç–µ–π–ª—å–Ω—ã—Ö –±–∞—Ä–æ–≤ –∏–∑ CSV —Ñ–∞–π–ª–∞
"""

import csv
import os
import sys
from datetime import datetime
from sqlalchemy.exc import IntegrityError

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from apps.core.db import SessionLocal
from apps.places.models import Place

def add_cocktail_bars(file_path: str):
    """–î–æ–±–∞–≤–∏—Ç—å –∫–æ–∫—Ç–µ–π–ª—å–Ω—ã–µ –±–∞—Ä—ã –∏–∑ CSV"""
    db = SessionLocal()
    added_count = 0
    skipped_count = 0
    total_rows = 0
    used_urls = set()

    try:
        with open(file_path, mode='r', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            places_to_add = []
            
            for row in reader:
                total_rows += 1
                name = row.get('name')
                description_full = row.get('description_full')
                source_url = row.get('source_url')

                if not name or not description_full:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –º–µ—Å—Ç–æ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∏–º–µ–Ω–∏ –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è: {row}")
                    skipped_count += 1
                    continue

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π source_url –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
                if not source_url:
                    base_url = f"cocktail_bars_{name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace('‚Äî', '_').replace('.', '').replace(',', '').replace('&', 'and').replace(':', '').replace('!', '').replace('?', '').replace('#', '').replace('/', '_')}"
                else:
                    # –ï—Å–ª–∏ source_url —É–∂–µ –µ—Å—Ç—å, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
                    base_url = f"cocktail_bars_{source_url.replace('https://', '').replace('http://', '').replace('www.', '').replace('/', '_').replace('.', '_')}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å URL
                counter = 1
                final_source_url = base_url
                while final_source_url in used_urls:
                    final_source_url = f"{base_url}_{counter}"
                    counter += 1
                
                used_urls.add(final_source_url)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                existing_place = db.query(Place).filter(
                    (Place.name == name) | (Place.source_url == final_source_url)
                ).first()

                if existing_place:
                    skipped_count += 1
                    continue

                new_place = Place(
                    name=name,
                    description_full=description_full,
                    category="bar",
                    processing_status="new",
                    source="cocktail_bars_batch",
                    source_url=final_source_url,
                    scraped_at=datetime.now()
                )
                places_to_add.append(new_place)

            if places_to_add:
                db.bulk_save_objects(places_to_add)
                db.commit()
                added_count = len(places_to_add)

    except IntegrityError as e:
        db.rollback()
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
    except Exception as e:
        db.rollback()
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
    finally:
        db.close()

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
    print(f"  –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –º–µ—Å—Ç: {added_count}")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç): {skipped_count}")
    print(f"  –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_rows}")

if __name__ == "__main__":
    csv_file_path = '../docs/places.csv/Bars___Craft__Speakeasy__Cocktails__Batch_.csv'
    print(f"üöÄ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–∫—Ç–µ–π–ª—å–Ω—ã—Ö –±–∞—Ä–æ–≤ –∏–∑ {csv_file_path.split('/')[-1]}\n" + "="*60)
    add_cocktail_bars(csv_file_path)
